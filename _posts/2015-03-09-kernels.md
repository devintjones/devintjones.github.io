---
layout: post
title: Kernels
category: Adv. Machine Learning
tags : [kernels]
---

#Probability Kernels 
Probabilistic Kernel - must satisfy triangular inequality

## Kullback-Leibler divergence
* natural distance between probabilities
* but is assymetric

Related:
### Jensen-Shannon
### Symmetrized KL

## Fischer Kernels/information

## Bhattacharyya Kernel

Kernel betw distributions that gives Hellinger divergence

* A slight generalization is the Probability Product Kernel
* p=1/2 => Bhattacharyya Kernel
* p=1 => expected likelihood kernel

## Gaussian Product Kernels
If mu = x and mu` = x`,
Same as RBF



For Gaussians with variable covariance,
Fisher kernel is a quadratic kernel

## Multinomial product kernels
Method for computing similarity of multi class distributions

Fisher kernel turns out to be linear

## Exponential Family Kernels
Same form across most classic distributions
Compute Bhattacharyya Kernel for the e-family
* Only dpends on convex comulant-generating function K(q)

Fisher Kernel is always linear in sufficient stats

## Mixture Product Kernels
Like a kernel of GMM

## HMM Product Kernel
Computes divergence of 2 HMMs
* If computed outright, it is inefficient: Computes cross product of all hidden variables

Use junction tree algorithm to comuter diffrence of only common parents - signficantly reduce copmlexity

## Sampling Product Kernels
Use generative model to apaproximate probability product via sample



